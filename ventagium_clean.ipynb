{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento, transformacion y limpieza\n",
    "\n",
    "### Venatgium Data Consulting\n",
    "**Mariana Aguado Muñoz Ledo**\n",
    "\n",
    "En este notebook se realizará el procesamiento, transformación y limpieza de un conjunto de datos denominados M5 donde se puede ver un conjunto de datos redactando los datos de ventas de diez tiendas walmart y sus ventas a lo largo de 5 años, estos datos fueron extraidos del siguiente [link](https://www.kaggle.com/competitions/m5-forecasting-accuracy/data).\n",
    "\n",
    "La base de datos cuenta de 5 datasets distintos, solo utilizaremos tres de ellos, que serán: una tabla de calendario (***calendar***), una tabla de la historia de ventas (***sales_train_evaluation***) y una tabla con información de los precios de venta (***sell_prices***). Se cargarán y revisarán los datos, y se hará una transformación y limpieza de llos para finalmente tener un .csv listo para analizarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librerias \n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos\n",
    "Comenzaremos leyendo los datasets en format .csv mostrando las primeras filas de los dataset, y observando las columnas y el tipo de columnas presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/marianaaguadomunozledo/Downloads/m5-forecasting-accuracy/'\n",
    "\n",
    "calendar = pd.read_csv(f'{DATA_PATH}calendar.csv')\n",
    "sales = pd.read_csv(f'{DATA_PATH}sales_train_evaluation.csv')\n",
    "sales_train_validation = pd.read_csv(f'{DATA_PATH}sales_train_validation.csv')\n",
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sell_prices = pd.read_csv(f'{DATA_PATH}sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  \n",
       "2          NaN          NaN          NaN        0        0        0  \n",
       "3          NaN          NaN          NaN        1        1        0  \n",
       "4          NaN          NaN          NaN        1        0        1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.head()\n",
    "#calendar.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
       "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
       "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
       "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
       "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       3       3       0       1  \n",
       "1       0       0       0       0       0  \n",
       "2       0       2       3       0       1  \n",
       "3       1       3       0       2       6  \n",
       "4       0       0       2       1       0  \n",
       "\n",
       "[5 rows x 1947 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()\n",
    "#sales_train_evaluation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price\n",
       "0     CA_1  HOBBIES_1_001     11325        9.58\n",
       "1     CA_1  HOBBIES_1_001     11326        9.58\n",
       "2     CA_1  HOBBIES_1_001     11327        8.26\n",
       "3     CA_1  HOBBIES_1_001     11328        8.26\n",
       "4     CA_1  HOBBIES_1_001     11329        8.26"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sell_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de calendar:\n",
      "date            object\n",
      "wm_yr_wk         int64\n",
      "weekday         object\n",
      "wday             int64\n",
      "month            int64\n",
      "year             int64\n",
      "d               object\n",
      "event_name_1    object\n",
      "event_type_1    object\n",
      "event_name_2    object\n",
      "event_type_2    object\n",
      "snap_CA          int64\n",
      "snap_TX          int64\n",
      "snap_WI          int64\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos de sales:\n",
      "id          object\n",
      "item_id     object\n",
      "dept_id     object\n",
      "cat_id      object\n",
      "store_id    object\n",
      "             ...  \n",
      "d_1937       int64\n",
      "d_1938       int64\n",
      "d_1939       int64\n",
      "d_1940       int64\n",
      "d_1941       int64\n",
      "Length: 1947, dtype: object\n",
      "\n",
      "Tipos de datos de sell_prices:\n",
      "store_id       object\n",
      "item_id        object\n",
      "wm_yr_wk        int64\n",
      "sell_price    float64\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"calendar\": calendar,\n",
    "    \"sales\": sales,\n",
    "    \"sell_prices\": sell_prices\n",
    "}\n",
    "\n",
    "for df_name, df in dataframes.items():\n",
    "    print(f\"Tipos de datos de {df_name}:\\n{df.dtypes}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los resultados anteriores podemos ver lo siguiente de cada uno de los datasets:\n",
    "\n",
    "1. **Calendar:** Este dataset contiene información relacionada con fechas y eventos. Incluye variables categóricas como weekday (día de la semana) y event_name_1 (nombres de eventos), así como numéricas como wm_yr_wk (año y semana), month, year, y flags binarios como snap_CA, snap_TX, y snap_WI.\n",
    "\n",
    "2. **Sales Train Evaluation:** Este dataset detalla las ventas diarias de productos específicos en varias tiendas. Contiene identificadores categóricos como id, item_id (producto), dept_id (departamento), cat_id (categoría), y store_id (tienda). Además, incluye un gran número de columnas numéricas (d_1937 a d_1941) que representan las ventas diarias para diferentes días.\n",
    "\n",
    "5. **Sell Prices:** Este dataset incluye información sobre los precios de los productos en diferentes tiendas. Contiene identificadores como store_id y item_id, junto con una columna numérica wm_yr_wk que relaciona los precios con una semana específica, y sell_price, que representa el precio de venta como un valor decimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza y transformación de datos\n",
    "\n",
    "Despues de una exploración de los datos se puede ver que es posible realizar análisis de distintos tipos dependiendo el propósito y requisitos del estudio. Comenzaremos por prepara los dataframes para despues unirlos en un único df.\n",
    "\n",
    "Además, se puede ver en los datos que existen muchos campos de columnas que no estan bien clasificados, por ejemplo que se espera que sea numerico y en su lugar es un ***object*** esto puede indicar que hay valores faltantes (o NULL) o algun otro tipo de lectura inusual por lo que se debe tratar antes de analizar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comenzo por transformar las columnas \"d...\" del conjunto de ventas para pasar de un formato ancho a un formato largo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_melted = pd.melt(sales, \n",
    "                            id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n",
    "                            var_name='d', \n",
    "                            value_name='sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, se unieron los conjuntos de datos de ventas y calendario:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(sales_melted, calendar, on='d', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   id            object\n",
      " 1   item_id       object\n",
      " 2   dept_id       object\n",
      " 3   cat_id        object\n",
      " 4   store_id      object\n",
      " 5   state_id      object\n",
      " 6   d             object\n",
      " 7   sales         int64 \n",
      " 8   date          object\n",
      " 9   wm_yr_wk      int64 \n",
      " 10  weekday       object\n",
      " 11  wday          int64 \n",
      " 12  month         int64 \n",
      " 13  year          int64 \n",
      " 14  event_name_1  object\n",
      " 15  event_type_1  object\n",
      " 16  event_name_2  object\n",
      " 17  event_type_2  object\n",
      " 18  snap_CA       int64 \n",
      " 19  snap_TX       int64 \n",
      " 20  snap_WI       int64 \n",
      "dtypes: int64(8), object(13)\n",
      "memory usage: 9.3+ GB\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos optimizando el conjunto de datos eliminando columnas redundantes o innecesarias, como identificadores repetitivos (id, d) y datos menos relevantes para el análisis, como nombres de eventos repetitivos (event_name_2, event_type_2) y variables relacionadas con SNAP (snap_CA, snap_TX, snap_WI). Además, convertimos la columna date de tipo object a formato datetime, lo que reduce el uso de memoria y facilita el análisis temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas restantes en merged_data:\n",
      "Index(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'sales', 'date',\n",
      "       'wm_yr_wk', 'wday', 'month', 'year', 'event_name_1', 'event_type_1',\n",
      "       'snap_CA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'date' a formato datetime\n",
    "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
    "\n",
    "# Eliminar las columnas seleccionadas\n",
    "columns_to_drop = [\n",
    "    'id', 'd', 'weekday', \n",
    "    'event_name_2', 'event_type_2', \n",
    "    'snap_TX', 'snap_WI'\n",
    "]\n",
    "merged_data = merged_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Verificar las columnas restantes\n",
    "print(\"Columnas restantes en merged_data:\")\n",
    "print(merged_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se incorporó el conjunto de precios para tener un solo conjunto de datos final:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.merge(merged_data, sell_prices, how='left', on=['store_id', 'item_id', 'wm_yr_wk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id    dept_id   cat_id store_id state_id  sales       date  \\\n",
       "0  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA      0 2011-01-29   \n",
       "1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA      0 2011-01-29   \n",
       "2  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA      0 2011-01-29   \n",
       "3  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA      0 2011-01-29   \n",
       "4  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA      0 2011-01-29   \n",
       "\n",
       "   wm_yr_wk  wday  month  year event_name_1 event_type_1  snap_CA  sell_price  \n",
       "0     11101     1      1  2011          NaN          NaN        0         NaN  \n",
       "1     11101     1      1  2011          NaN          NaN        0         NaN  \n",
       "2     11101     1      1  2011          NaN          NaN        0         NaN  \n",
       "3     11101     1      1  2011          NaN          NaN        0         NaN  \n",
       "4     11101     1      1  2011          NaN          NaN        0         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos los valores únicos en algunas columnas de interés para revisar que información podemos obtener de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dept_id          7\n",
      "cat_id           3\n",
      "state_id         3\n",
      "event_name_1    30\n",
      "event_type_1     4\n",
      "dtype: int64\n",
      "Valores únicos en dept_id: ['HOBBIES_1' 'HOBBIES_2' 'HOUSEHOLD_1' 'HOUSEHOLD_2' 'FOODS_1' 'FOODS_2'\n",
      " 'FOODS_3']\n",
      "Valores únicos en cat_id: ['HOBBIES' 'HOUSEHOLD' 'FOODS']\n",
      "Valores únicos en state_id: ['CA' 'TX' 'WI']\n",
      "Valores únicos en event_name_1: [nan 'SuperBowl' 'ValentinesDay' 'PresidentsDay' 'LentStart' 'LentWeek2'\n",
      " 'StPatricksDay' 'Purim End' 'OrthodoxEaster' 'Pesach End']\n",
      "Valores únicos en event_type_1: [nan 'Sporting' 'Cultural' 'National' 'Religious']\n",
      "Valores únicos en snap_CA: [0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_counts = final_data[['dept_id', 'cat_id', 'state_id', 'event_name_1', 'event_type_1']].nunique()\n",
    "print(unique_counts)\n",
    "\n",
    "unique_values_dept_id = final_data['dept_id'].unique()\n",
    "unique_values_cat_id = final_data['cat_id'].unique()\n",
    "unique_values_state_id = final_data['state_id'].unique()\n",
    "unique_values_event_name_1 = final_data['event_name_1'].unique()\n",
    "unique_values_event_type_1 = final_data['event_type_1'].unique()\n",
    "unique_values_snap_CA = final_data['snap_CA'].unique()\n",
    "\n",
    "\n",
    "# Imprimir algunos de los resultados si es necesario\n",
    "print(\"Valores únicos en dept_id:\", unique_values_dept_id[:10])  # Solo los primeros 10\n",
    "print(\"Valores únicos en cat_id:\", unique_values_cat_id[:10])\n",
    "print(\"Valores únicos en state_id:\", unique_values_state_id[:10])\n",
    "print(\"Valores únicos en event_name_1:\", unique_values_event_name_1[:10])\n",
    "print(\"Valores únicos en event_type_1:\", unique_values_event_type_1[:10])\n",
    "print(\"Valores únicos en snap_CA:\", unique_values_snap_CA[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar este analisis se tomarán únicamente las tiendas en el estado de California, esto con el supuesto de que se realiza el análisis para un directivo de Walmart en CA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = final_data[final_data['state_id'] == 'CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se elimna las variables que no necesitamos y se libera memoria para continuar trabajandi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos otras columnas innecesarias y variables que ya no se necesitan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['store_id', 'state_id', 'wm_yr_wk']\n",
    "df = df_filtered.drop(columns=columns_to_drop)\n",
    "\n",
    "del columns_to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23672436 entries, 0 to 59162795\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   item_id       object        \n",
      " 1   dept_id       object        \n",
      " 2   cat_id        object        \n",
      " 3   sales         int64         \n",
      " 4   date          datetime64[ns]\n",
      " 5   wday          int64         \n",
      " 6   month         int64         \n",
      " 7   year          int64         \n",
      " 8   event_name_1  object        \n",
      " 9   event_type_1  object        \n",
      " 10  snap_CA       int64         \n",
      " 11  sell_price    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos\n",
    "\n",
    "Se empezará por revisar y manejar los datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/fgv8253x1zzfjqd3mcbp816m0000gn/T/ipykernel_66864/3045100278.py:1: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/marianaaguadomunozledo/Downloads/df_ventagium.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/marianaaguadomunozledo/Downloads/df_ventagium.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes en cada columna:\n",
      "event_name_1    21745468\n",
      "event_type_1    21745468\n",
      "item_id                0\n",
      "dept_id                0\n",
      "cat_id                 0\n",
      "sales                  0\n",
      "date                   0\n",
      "wday                   0\n",
      "month                  0\n",
      "year                   0\n",
      "snap_CA                0\n",
      "sell_price             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Valores faltantes en cada columna:\")\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, únicamente tenemos valores nulos en los eventos (pues no hay eventos a diario) y en *sell_price*. Se imputará los datos nulos empleando la mediana del precio según el producto en cuestión, garantizando que los valores sean reemplazados con un estimado apropiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sell_price'] = df.groupby('item_id')['sell_price'].transform(lambda x: x.fillna(x.median()))\n",
    "df['sell_price'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23672436 entries, 0 to 59162795\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   item_id       object        \n",
      " 1   dept_id       object        \n",
      " 2   cat_id        object        \n",
      " 3   sales         int64         \n",
      " 4   date          datetime64[ns]\n",
      " 5   wday          int64         \n",
      " 6   month         int64         \n",
      " 7   year          int64         \n",
      " 8   event_name_1  object        \n",
      " 9   event_type_1  object        \n",
      " 10  snap_CA       int64         \n",
      " 11  sell_price    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, revisemos si existen duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas: 11088680\n",
      "                item_id    dept_id   cat_id  sales       date  wday  month  \\\n",
      "3049      HOBBIES_1_001  HOBBIES_1  HOBBIES      0 2011-01-29     1      1   \n",
      "3050      HOBBIES_1_002  HOBBIES_1  HOBBIES      0 2011-01-29     1      1   \n",
      "3051      HOBBIES_1_003  HOBBIES_1  HOBBIES      0 2011-01-29     1      1   \n",
      "3053      HOBBIES_1_005  HOBBIES_1  HOBBIES      0 2011-01-29     1      1   \n",
      "3054      HOBBIES_1_006  HOBBIES_1  HOBBIES      0 2011-01-29     1      1   \n",
      "...                 ...        ...      ...    ...        ...   ...    ...   \n",
      "59162785    FOODS_3_817    FOODS_3    FOODS      0 2016-05-22     2      5   \n",
      "59162788    FOODS_3_820    FOODS_3    FOODS      1 2016-05-22     2      5   \n",
      "59162789    FOODS_3_821    FOODS_3    FOODS      0 2016-05-22     2      5   \n",
      "59162792    FOODS_3_824    FOODS_3    FOODS      0 2016-05-22     2      5   \n",
      "59162795    FOODS_3_827    FOODS_3    FOODS      0 2016-05-22     2      5   \n",
      "\n",
      "          year event_name_1 event_type_1  snap_CA  sell_price  \n",
      "3049      2011          NaN          NaN        0        8.26  \n",
      "3050      2011          NaN          NaN        0        3.97  \n",
      "3051      2011          NaN          NaN        0        2.97  \n",
      "3053      2011          NaN          NaN        0        2.98  \n",
      "3054      2011          NaN          NaN        0        1.00  \n",
      "...        ...          ...          ...      ...         ...  \n",
      "59162785  2016          NaN          NaN        0        2.94  \n",
      "59162788  2016          NaN          NaN        0        1.98  \n",
      "59162789  2016          NaN          NaN        0        4.98  \n",
      "59162792  2016          NaN          NaN        0        2.48  \n",
      "59162795  2016          NaN          NaN        0        1.00  \n",
      "\n",
      "[11088680 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df.duplicated()\n",
    "\n",
    "# Contar el número de filas duplicadas\n",
    "num_duplicated_rows = df.duplicated().sum()\n",
    "print(f\"Número de filas duplicadas: {num_duplicated_rows}\")\n",
    "\n",
    "# Mostrar las filas duplicadas si existen\n",
    "df_duplicated = df[df.duplicated()]\n",
    "print(df_duplicated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos 11088680 filas duplicadas, tienen que ser eliminadas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas después de eliminar: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "num_duplicated_rows = df.duplicated().sum()\n",
    "print(f\"Número de filas duplicadas después de eliminar: {num_duplicated_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos el conjunto de datos final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/marianaaguadomunozledo/Downloads/df_ventagium.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
